<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    
    <title>第三十六次 PFCC 会议｜Ivy 与 PaConvert 分享 | 飞桨开源社区博客</title>
    <meta name="description" content="Wonderful stories from PaddlePaddle contributors">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/assets/style.BId5x853.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.Cce2DscU.js"></script>
    <link rel="modulepreload" href="/assets/chunks/theme.DU_EuCD6.js">
    <link rel="modulepreload" href="/assets/chunks/framework.BRsttz9t.js">
    <link rel="modulepreload" href="/assets/chunks/MessageBox.WSXlZHbS.js">
    <link rel="modulepreload" href="/assets/posts_pfcc-36th.md.7668E08h.lean.js">
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="theme-color" content="#ffffff">
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon-180x180.png">
    <link rel="mask-icon" href="/icons/mask-icon.svg" color="#ffffff">
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7XR50K1YRK"></script>
    <script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-7XR50K1YRK");</script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
    <link rel="manifest" href="/manifest.webmanifest">
  </head>
  <body>
    <div id="app"><div class="antialiased dark:bg-neutral-900 min-h-screen"><div class="max-w-3xl mx-auto px-4 sm:px-6 xl:max-w-5xl xl:px-0"><nav class="flex justify-between items-center py-10 font-bold"><a class="text-xl" href="/" aria-label="飞桨开源社区博客"><img class="inline-block mr-2" style="width:120px;" alt="logo" src="/logo.png"><span class="hidden md:inline dark:text-white">飞桨开源社区博客</span></a><div class="text-sm text-gray-500 dark:text-white leading-5"><a class="hover:text-gray-700 dark:hover:text-gray-200" href="https://github.com/PFCCLab/blog" target="_blank" rel="noopener"><span class="hidden sm:inline">GitHub </span>Source</a><span class="mr-2 ml-2">·</span><a class="hover:text-gray-700 dark:hover:text-gray-200" href="/about.html" rel="noopener">About</a><span class="mr-2 ml-2">·</span><a class="hover:text-gray-700 dark:hover:text-gray-200" href="https://github.com/PFCCLab" target="_blank" rel="noopener">PFCCLab →</a></div></nav></div><main class="max-w-3xl mx-auto px-4 sm:px-6 xl:max-w-5xl xl:px-0"><article class="xl:divide-y xl:divide-gray-200 dark:xl:divide-slate-200/5"><header class="pt-6 xl:pb-10 space-y-1 text-center"><dl><dt class="sr-only">Published on</dt><dd class="text-base leading-6 font-medium text-gray-500 dark:text-gray-300"><time datetime="2024-03-29T12:00:00.000Z">2024年3月29日</time></dd></dl><h1 class="text-3xl leading-9 font-extrabold text-gray-900 dark:text-white tracking-tight sm:text-4xl sm:leading-10 md:text-5xl md:leading-14">第三十六次 PFCC 会议｜Ivy 与 PaConvert 分享</h1></header><div class="divide-y xl:divide-y-0 divide-gray-200 dark:divide-slate-200/5 xl:grid xl:grid-cols-4 xl:gap-x-10 pb-16 xl:pb-20" style="grid-template-rows:auto 1fr;"><dl class="pt-6 pb-10 xl:pt-11 xl:border-b xl:border-gray-200 dark:xl:border-slate-200/5"><dt class="sr-only">Authors</dt><dd><ul class="flex flex-col pl-10 gap-y-5 md:grid md:grid-cols-2 md:gap-x-8 md:gap-y-6 md:pl-0 lg:grid-cols-3 xl:block xl:space-y-8"><!--[--><li class="flex items-center space-x-2"><img src="https://github.com/sunzhongkai588.png" alt="author image" class="w-10 h-10 rounded-full"><dl class="text-sm font-medium leading-5 whitespace-nowrap"><dt class="sr-only">Name</dt><dd class="text-gray-900 dark:text-white">孙师傅</dd><dt class="sr-only">GitHub</dt><dd><a href="https://github.com/sunzhongkai588" target="_blank" rel="noopnener noreferrer" class="link">@sunzhongkai588</a></dd></dl></li><li class="flex items-center space-x-2"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-full"><dl class="text-sm font-medium leading-5 whitespace-nowrap"><dt class="sr-only">Name</dt><dd class="text-gray-900 dark:text-white">Daniel（英国小哥）</dd><dt class="sr-only">GitHub</dt><dd><a href="https://github.com/djl11" target="_blank" rel="noopnener noreferrer" class="link">@djl11</a></dd></dl></li><li class="flex items-center space-x-2"><img src="https://github.com/RedContritio.png" alt="author image" class="w-10 h-10 rounded-full"><dl class="text-sm font-medium leading-5 whitespace-nowrap"><dt class="sr-only">Name</dt><dd class="text-gray-900 dark:text-white">莱师傅</dd><dt class="sr-only">GitHub</dt><dd><a href="https://github.com/RedContritio" target="_blank" rel="noopnener noreferrer" class="link">@RedContritio</a></dd></dl></li><!--]--></ul></dd></dl><div class="divide-y divide-gray-200 dark:divide-slate-200/5 xl:pb-0 xl:col-span-3 xl:row-span-2"><div style="position:relative;" class="prose dark:prose-invert max-w-none pt-10 pb-8"><div><p>在第 36 次 PFCC 会议上，我们有幸邀请了 Ivy 社区的英国小哥 Daniel（<a href="https://github.com/djl11" target="_blank" rel="noreferrer">@djl11</a>）和 Paddle 社区开发者莱师傅（<a href="https://github.com/tink2123" target="_blank" rel="noreferrer">@RedContritio</a>）分别分享了代码转换工具 Ivy、PaConvert。</p><h2 id="会议议程" tabindex="-1">会议议程 <a class="header-anchor" href="#会议议程" aria-label="Permalink to &quot;会议议程&quot;">​</a></h2><ol><li><p>如何通过 <a href="https://github.com/unifyai/ivy" target="_blank" rel="noreferrer">Ivy</a> 将 PyTorch 和 TensorFlow 模型进行转换，并直接在 Paddle 项目中使用。（35 min） <a href="https://github.com/djl11" target="_blank" rel="noreferrer">@djl11</a></p><ul><li>demo：<a href="https://unify.ai/docs/ivy/demos/examples_and_demos/dinov2_to_paddle.html" target="_blank" rel="noreferrer">How To Convert Models from PyTorch to PaddlePaddle</a></li><li>QA 环节</li></ul><div style="display:flex;justify-content:center;"><figure style="width:100%;"><img src="/assets/cut-1.WioqBQsV.png"><figcaption>Ivy 模型转换 demo 讲解（截图）</figcaption></figure></div></li><li><p><a href="https://github.com/tink2123" target="_blank" rel="noreferrer">@RedContritio</a> <a href="https://github.com/PaddlePaddle/PaConvert" target="_blank" rel="noreferrer">PaConvert</a> 代码转换工具介绍 （10 ～ 20min）</p><ul><li>PaConvert 介绍</li><li>QA 环节</li></ul><div style="display:flex;justify-content:center;"><figure style="width:100%;"><img src="/assets/cut-2.DTE8mGwP.png"><figcaption>PaConvert 介绍（截图）</figcaption></figure></div></li></ol><blockquote><p>会议材料及回放见百度网盘链接: <a href="https://pan.baidu.com/s/16vAVoXpCgdrrRK5e_-w7Ig" target="_blank" rel="noreferrer">https://pan.baidu.com/s/16vAVoXpCgdrrRK5e_-w7Ig</a> ，提取码见 PFCC 微信群公告。</p></blockquote><h2 id="qa-环节" tabindex="-1">QA 环节 <a class="header-anchor" href="#qa-环节" aria-label="Permalink to &quot;QA 环节&quot;">​</a></h2><p>所有 QA 内容均已记录在<a href="https://github.com/PaddlePaddle/community/blob/master/pfcc/meetings/2024/2024-03-13-meeting-minutes.md" target="_blank" rel="noreferrer">「第三十六次 PFCC 会议纪要」</a>中。</p><h3 id="part-1-ivy-部分" tabindex="-1">Part-1： Ivy （部分） <a class="header-anchor" href="#part-1-ivy-部分" aria-label="Permalink to &quot;Part-1： Ivy （部分）&quot;">​</a></h3><ul><li><p><strong>问题 1：</strong> 你有测试过多少模型能够转换成功？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 目前测试了 30 个主流模型，均能转换成功。目前我们正在测试更多 hugging face 上的模型，大概 70 ～ 75% 能够转换成功。我们也欢迎和鼓励社区告诉我们哪些模型无法有效转换，我们有信心能够解决这些问题。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 2：</strong> 对于成功转换的模型，它会影响性能吗？或者可能需要更多的时间来训练嘛？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 这是一个好问题，也是我们目前正在测试的东西。我们现在看到在 Paddle 上会有 30% 到 40% 的性能损失， 这是因为在我们的 Paddle 后端上有一些低效，我们目前正在努力解决这个问题。 <br> 性能问题取决于模型，但通常来讲并不会影响训练性能。当我们从 Pytorch 转换到 Tensorflow 时，经常看到训练速度的提高。特别是当我们从一个框架转化到 Jax，经常看到一个大幅度的提升，尤其是在 TPU 上。 <br> 所以可能有一些开销，但总的来讲不会有特别大幅度的降低。即使存在个别问题，我们也会很快修复他们。话说回来，这也是一个长期的过程，因为我们正在开发许多不同的框架，并与许多不同的生态伙伴合作。我们把精力集中在用户反馈的真实用例上，而不是试图修复所有东西。所以当你使用过程中确实出问题了，请在 discord 上联系我们，我们会把它添加到高优先级的列表中，并尽快解决。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 3：</strong> 请问是否有覆盖率相关的工作，类似 PyTorch 那样对后端支持覆盖率有表单或者对应的 CI 流水线</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 我们做覆盖的方式是详尽的单元测试，所以答案是有。我们在 Github 上 的 CI 已经达到了最大值，我们一直在运行单元测试，在 CPU 和 GPU 上测试每个框架、每个函数，所以我们确实有扩展函数覆盖范围。 <br> 但在每个设备上，支持每个框架、每个版本的每个功能，是一个非常大的、指数爆炸级的工作。基本上有数百万个这样的测试。所以我们真正关注的是什么？这是一个很长的答案，但就像生活中的许多事情一样，我们需要关注重要的事情。我们把更多的注意力放在真正常见的函数上（relu、add、matmul 等）那些真正不常见的、较少使用的函数，我们关注的比较少。在我们看来，我们可能永远不会达到完全覆盖，但只要覆盖到 99% 的模型就是 OK 的，这比支持每个版本每个函数更重要。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 4：</strong> PyTorch 大概有两千多个 API，包括很多废弃的、不常见的 API，有多少可以通过 Ivy 转换？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 我们只关注当前最新版本的 pytorch，以及其 functional API。 在 ivy/functional/frontends 你可以看到所有这些细节，包括我们在每个框架中都支持什么。 <br> 主要的一点是我们支持 functional API，但我们不支持 ATen。我们并不把转换限制在 ATen 或很小的范围内（比如组成所有函数的函数子集），我们可以这么做，但不这样做的原因是我们想更高级别的代码转换。某种程度上，函数的越高层越好，因为当我们从高层 PyTorch 函数转换到高层 ivy 函数、高层 Tensorflow 函数时，把函数拆分成更小单位仍然是有可能的。但如果将底层 OP 重新创建为目标框架中能被优化的高级函数，要困难得多。这就是为什么我们专注于 functional API 和高级函数更重要（但我们也不重新实现的 class）。 <br> 这是一个很长的回答，但这是有意义的。不过我们看到了良好的覆盖率，看到绝大多数模型都能正确转换。我们鼓励人们尝试它，如果它不起作用，让我们知道，我们会让它起作用。 <!--]--></div></div></li><!--]--></ul><blockquote><p>编者注：细节戳 ➡️ <a href="https://github.com/unifyai/ivy/tree/main/ivy/functional/frontends" target="_blank" rel="noreferrer">ivy/functional/frontends</a></p></blockquote></li><li><p><strong>问题 5：</strong> 我们刚看到的前端，目前支持了很多。但现在还有很多 API 不能转换，那我该怎么做？怎么处理它们？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 基本上，如果我们看到开发者对某 API 有足够的兴趣，届时我们会支持。对于不那么常见的 API，Ivy 也是可以支持这些的。如果有一个模型不能转换成功，而我们有信心能让他转换成功，那么我们可以添加对那些 API 的支持。 <br> 如果用户有自定义的 C++ 代码，那么默认情况下不能转换，但我们提供一个接口，你可以在其中指定 C++ 的 torch 实现，这样就可以转换了。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 6：</strong> PyTorch API 有很多参数，不同参数可以组成各种组合，如果某些参数不支持，则如何处理？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 基本上我们支持 PyTorch 的所有行为，包括所有额外的参数等。我们通过构建基于 Ivy 的统一的 functional API（如 ivy.matmul、ivy.add、ivy.reshape 等），重新创建 PyTorch 函数，以完美模仿 PyTorch 的任何可能行为。这可能需要一个 Ivy 函数来重新创建，但如果是一个具有多种不同模式的复杂 Python 函数，可能就需要十个。然后，使用 Ivy 重新创建所有这些行为，每个 Ivy 函数都有特定的 Paddle 后端。因此，一个 PyTorch 函数可能需要多个 Ivy 函数，而这些 Ivy 函数又可能需要多个 Paddle 函数来完全重新创建该行为。所有变体、额外的参数和边缘情况都可以通过中间表示和 API 得到支持。在这些情况下，需要将其作为 Paddle 函数的组合重新创建，尽管这可能以运行时间速度为代价，但通常不会看到大的损失。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 7：</strong> 目前大模型很流行。对于预训练的大模型，有大量的预训练权重，是否有更快的方式进行转换。</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 在从 PyTorch 转换模型到 Paddle 后，因为现在 Paddle 模型就是一个加强版的 PyTorch 模型，转换权重可以相对简单，比如将它们转换为 Numpy 数组，然后加载到 Paddle 中。实际上，Ivy 在模型转换过程中，会自动把所有的 PyTorch 权重转换为 Paddle 权重。 <br> 目前没有更快的转换方式，通常使用 DLPack（张量数据结构的中间表示标准）作为中间件，但由于不同框架对 DLPack 的支持不一致，最终选择使用 Numpy 作为中介。我们把将权重转移到 CPU，以高精度格式存储并转换为 Numpy 数组，然后转移到新框架中，这种方法在 demo 演示中以及对于大型模型都能很好地工作。 <br> 实际上目前的转换是基于 function tracing，如果大型语言模型需要多个 GPU 运行，这可能会有些复杂。不过，我们将很快转向使用纯 symbolic tracing 方法，届时就不需要存储所有权重和中间数组，而是基于符号追踪的代理数组，这将意味着不需要启动大量 GPU 来完成函数追踪。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 8：</strong> 当引入一个新 API 时，支持新 API 的成本有多大？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 从工程成本的角度来看，支持一个新 API 并不困难，也不是我们特别关注的问题。我们大部分时间都花在了 function tracing 的逻辑、抽象语法树（AST）逻辑以及编译器和追踪器上。 <br> 添加一个新的前端功能并不难，做起来相当快速和容易。事实上，所有前端 API 和后端 API 都是完全开源的（Apache 2 许可），任何人都可以为其贡献代码。如果在转换模型时失败，并且报错消息指出模型转换失败是因为缺少来自 Ivy/PyTorch 前端的某个函数，我们还提供了如何提交拉取请求以及如何自行添加该功能的链接。真正困难的部分是处理动态控制流、以可扩展的方式进行函数追踪、获取正确的抽象语法树表示，这些都是与框架无关的工作，我们以一种不特定于任何框架的方式进行这些工作。因此，简短的回答是添加新 API 相对容易，真正困难的是其他部分。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 9：</strong> Ivy 是有特定的前端 API，还是只转译其他框架？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> Ivy 本身也是一个框架，拥有自己的前端 API（如 TensorFlow、PyTorch、JAX 等）以及自己的一套函数。Ivy 的 function API 有两个用途：第一个用途是作为一个中间表示，用于从一个框架转换到另一个框架，即 Ivy 的 API 充当中间表示；第二个用途是作为其自身的框架，允许直接在 Ivy 中编写新代码，可以在 Ivy 中编写整个模型，并使用 Ivy 类和 Ivy 函数，然后可以切换后端，使用 Paddle、TensorFlow、PyTorch 或 JAX 等。因此，Ivy 既能自身作为框架，也能转译其他框架。但我们认为最有价值并且最直接的是转译器功能，因为这样已有的所有代码都可以直接使用，而无需任何人编写新的 Ivy 代码。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 10：</strong> 听起来和 keras 很相似？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 是的！如果忽略前端，Ivy 和 Keras 非常相似。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 11：</strong> 我们是否需要使用更高的内存来转换模型？因为也许转换模型过程中需要保存中间信息，所以可能会占用一些内存。所以我想问问，像转换 llama 这样的大模型是否 ok？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 这是一个很好的问题。目前，鉴于转译器是基于函数追踪（function tracing）的，确实需要调用模型以追踪图（graph），这意味着在转换时需要能够对模型进行推理。现在，转换本身不需要在目标设备上进行，只要你有一台内存足够的机器，就可以在 CPU 上完成转换，并且默认情况下转换是在 CPU 上进行的，因为通常 CPU 有的 RAM 比 GPU 多。 <br> 在转译器的一个很旧的版本中，我们曾同时获取所有 PyTorch 权重和所有 Paddle 权重，并让它们同时存在于内存中，这是非常糟糕的做法。现在，权重从 A 转换到 B 是逐步进行的，我们先取第一个权重，将其转换为 Numpy，然后转换为 Paddle，接着转换第二个权重，这样我们就不会重复获取权重。但是，我们避免尽可能多的函数追踪（function tracing），我们现在有自己的 AST（抽象语法树）方法，这个方法工作得很好、非常稳定，我们正在与几家公司合作开发这一点。 <br> 最终设计基于 AST，基于符号追踪，我们将实际的函数追踪作为最后的手段，因此内存使用将会非常低。但是，正如你所说，现在确实需要一些 RAM 来转换一个非常大的模型，但希望在几个月内，这将不再是问题。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 12：</strong> 你如何平衡你的生活和工作，以及保持你对开源的热情呢？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 平衡生活和工作非常困难，但幸运的是，我真的很热爱我正在做的事情，这是保持我动力的原因。我们不仅仅是在做一个开源项目，还在建立一家公司，需要与客户进行沟通。虽然我是唯一的创始人（并非是原本的设计），而且这确实需要付出大量的工作，但我对统一人工智能领域的景象充满热情，总是对看到的碎片化情况感到沮丧，无论是在 AI 框架还是在大型语言模型（LMM）的领域。目前我们正在努力统一这些领域，保持激情和兴奋是我继续前进的动力，如果我不再感到兴奋，可能就不会那么有趣了。幸好，我始终保持着兴奋感，所以工作并不感觉艰难。确实，因为这些并不感觉像是工作，所以更容易保持。 <br> 此外，帝国理工学院的学习经历非常紧张，这让我掌握了之前缺少的知识教育和时间管理经验。 <br> 但我也要说，我会把周日作为休息日，我认为你也需要休息，否则很快就会感到疲惫不堪。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 13：</strong> 英国的人工智能环境怎么样？是否会有官方活动之类的？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/djl11.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">Daniel</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 英国的人工智能环境还是不错的。虽然我经常到处旅行，在欧洲和美国都呆过相当长的时间，所以并不算是英国本地人，但英国的 AI 环境绝对是值得关注的。比如，DeepMind 就设在英国，谷歌的主要 AI 分支也在伦敦。显然，Meta、亚马逊以及其他几家公司也在伦敦设有 AI 办公室。伦敦还有很多有趣的初创公司，所以我觉得很幸运能住在伦敦，特别是在靠近国王十字的伊斯灵顿区，那里可以说是整个科技圈的中心。我遇到的很多很酷的初创公司以及举办的活动数目都令人惊叹，所以我认为这里的环境非常好。我很高兴能在伦敦，与这么多创造酷炫事物的人在一起。 <br> 我认为最大的 AI 人才集中地是旧金山，那里又是另一个水平，但我仍感觉英国很棒，伦敦也很棒，虽然它还没有达到旧金山的水平，但也许将来会有所改变。 <!--]--></div></div></li><!--]--></ul></li></ul><h3 id="part-2-paconvert-部分" tabindex="-1">Part-2： PaConvert （部分） <a class="header-anchor" href="#part-2-paconvert-部分" aria-label="Permalink to &quot;Part-2： PaConvert （部分）&quot;">​</a></h3><ul><li><p><strong>问题 1 ：</strong> PaConvert 是否是根据 AST 转换模型的？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/RedContritio.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">RedContritio</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 是的，基于解析 python 源码，然后根据 AST 生成 Paddle 模型。 <!--]--></div></div></li><!--]--></ul></li><li><p><strong>问题 2 ：</strong> 是否有中间表示？还是直接将 PyTorch 代码转换成 Paddle ？</p><ul class="p-0"><!--[--><li class="flex items-start space-y-2 mr-10"><img src="https://github.com/RedContritio.png" alt="author image" class="w-10 h-10 rounded-md m-0"><div class="items-start flex flex-col px-3 !mt-0"><span class="text-neutral-500 dark:text-neutral-400">RedContritio</span><div class="inline-block bg-slate-200 px-2 py-2 rounded-md dark:bg-zinc-700"><!--[--> 直接转换，没有中间表示。 <!--]--></div></div></li><!--]--></ul></li></ul><blockquote><p>编者注 ✍️：主要是英国小哥在问莱师傅 😛</p></blockquote><h2 id="会议剪影" tabindex="-1">会议剪影 <a class="header-anchor" href="#会议剪影" aria-label="Permalink to &quot;会议剪影&quot;">​</a></h2><p><img src="/assets/cut-3.DykMff0-.png" alt="cut-3"></p></div></div></div><footer class="text-sm font-medium leading-5 divide-y divide-gray-200 dark:divide-slate-200/5 xl:col-start-1 xl:row-start-2"><div class="py-8"><h2 class="text-xs tracking-wide uppercase text-gray-500 dark:text-white"> Next Article </h2><div class="link"><a href="/posts/suzhou-kaifangyuanzi">PaddleOCR 算法模型挑战赛圆满落幕 &amp; 杭州开发者线下 Meetup</a></div></div><div class="py-8"><h2 class="text-xs tracking-wide uppercase text-gray-500 dark:text-white"> Previous Article </h2><div class="link"><a href="/posts/wangxin-story">【开源江湖闲聊录】Paddle 六边形战士？揭开汪师傅的神秘面纱～</a></div></div><div class="pt-8"><a class="link" href="/">← Back to the blog</a></div></footer></div></article></main></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about.md\":\"CzQAAf4V\",\"index.md\":\"AYBfx0e1\",\"pages_1.md\":\"wccGEy_C\",\"pages_2.md\":\"CNyCU79V\",\"pages_3.md\":\"B2EUOUN_\",\"pages_4.md\":\"JDLWzQTr\",\"pages_5.md\":\"wVTJN5qg\",\"pages_6.md\":\"ajK8Xo7n\",\"pages_7.md\":\"D1V8X6Zv\",\"pages_8.md\":\"C9fPTFNT\",\"posts_2023-os-report.md\":\"KoqxymVZ\",\"posts_2024-summary.md\":\"BFc6O-qh\",\"posts_2025-3rd-sw-conf.md\":\"oYRo7W4-\",\"posts_2025wuzhen.md\":\"Dc_dInmo\",\"posts_attention-sharing-sirui.md\":\"CZuKocbE\",\"posts_attnsink-paper-sharing.md\":\"RrNa11ke\",\"posts_buaa-starter.md\":\"DZMcxZ08\",\"posts_build-ernie-websearch.md\":\"NXDkfuT1\",\"posts_ccf-pku.md\":\"DBv8vhzc\",\"posts_chengdu-kaiyuanshe.md\":\"BuU5nIAV\",\"posts_chuan-story.md\":\"UiGi40mG\",\"posts_context-parrel-sharing.md\":\"BIHMolvU\",\"posts_cosyvoice.md\":\"BzDq48dR\",\"posts_decode-sparse-attention-method.md\":\"Ck9FTHi3\",\"posts_deepseek-tech-visualized.md\":\"BKbTJj_v\",\"posts_ernie45-paddleocr-case.md\":\"RR0g2AWK\",\"posts_first-post.md\":\"DfLGbfoW\",\"posts_flashoverlap-paper-sharing.md\":\"DxZQIYNn\",\"posts_flux-paper-sharing.md\":\"BI5_0SX0\",\"posts_glcc-luqi.md\":\"DiK5hFCr\",\"posts_hackathon-5th-episode01.md\":\"Df0O2ch6\",\"posts_hackathon-5th-episode02.md\":\"DljLYSrV\",\"posts_hackathon-5th-episode03.md\":\"B8-h4PLM\",\"posts_hackathon-6th-summary.md\":\"CjII45CK\",\"posts_hackathon-7th-summary.md\":\"BZoGEYXn\",\"posts_high-precision-rag-system.md\":\"CfUn4ZYF\",\"posts_huanggua-story.md\":\"3fmStkaX\",\"posts_huangjiyi-story.md\":\"DnuzI-cZ\",\"posts_ijcai-2024-competition.md\":\"B2ssZ-R3\",\"posts_io-paper-sharing.md\":\"DaAgwrgf\",\"posts_japan-hackathon.md\":\"B4r6pLgQ\",\"posts_kv-cache-drop-for-llm-infer.md\":\"FlfjGRC8\",\"posts_kv-cache-overview.md\":\"BLQqMIXC\",\"posts_lightning-talks.md\":\"CkzvQk5M\",\"posts_ligoml-story.md\":\"DwUUSbET\",\"posts_limin-story.md\":\"Cq3bk9v5\",\"posts_loaf-sharing.md\":\"Cb6ZXW4C\",\"posts_lzj-sharing.md\":\"VfbU8rSL\",\"posts_magiattention-sharing.md\":\"9uhQAeai\",\"posts_medusa.md\":\"CafSgstt\",\"posts_megascale-infer-paper-sharing.md\":\"DdCevYFk\",\"posts_netmoe-paper-sharing.md\":\"CLmhz_8_\",\"posts_newcomers-manual.md\":\"2fGdj5Uh\",\"posts_newhardware-2nd-event.md\":\"DP8zlBFH\",\"posts_nknan-story.md\":\"ClIDCktw\",\"posts_outlier-in-llm-paper-sharing.md\":\"DxJIzetH\",\"posts_pactguard-ernie-pp.md\":\"9blIBKHw\",\"posts_paddle-debug-methods.md\":\"BGwMbwTc\",\"posts_paddle-pipeline-parallel.md\":\"BXrwKs5W\",\"posts_paddle-scnu.md\":\"CsOmY_uw\",\"posts_paddleocr-release.md\":\"BW1kPCNf\",\"posts_paddleocr-vl-for-manga.md\":\"Dw-Lu7qS\",\"posts_pfcc-36th.md\":\"7668E08h\",\"posts_pku-course-2025.md\":\"Bo1xw7zs\",\"posts_pku-course.md\":\"B3Zt9sAI\",\"posts_post-training-overview.md\":\"bo23EEX8\",\"posts_pytorch-conference-01.md\":\"B14UyS7F\",\"posts_sanbu-story.md\":\"BVuipAfQ\",\"posts_shanghai-event.md\":\"ApG0YjGd\",\"posts_shun-story.md\":\"Bbt17jzP\",\"posts_starter-camp-5th.md\":\"5mxEq-BX\",\"posts_starter-camp.md\":\"TdAP6itn\",\"posts_suzhou-kaifangyuanzi.md\":\"CCEtzRNL\",\"posts_swagger-deepseek-r1.md\":\"BLYovS4m\",\"posts_tao-story.md\":\"VncVwA3l\",\"posts_type-hints-project.md\":\"BYrNy-i6\",\"posts_vattention-paper-sharing.md\":\"CXLeYUSG\",\"posts_wangxin-story.md\":\"B1ojKWVC\",\"posts_wuxi-kaifangyuanzi.md\":\"DVani9MK\",\"posts_xdoctest-project.md\":\"D1YjEXRk\",\"posts_xdu-xjtu-os.md\":\"CF04UOFz\",\"posts_xian-event.md\":\"DSOIzACM\",\"posts_yanguohao-story.md\":\"Caxzgkds\",\"posts_yinfan-story.md\":\"BQD8IBpP\",\"posts_zhangyiqiao-story.md\":\"D5MUTeFE\",\"posts_zheng-story.md\":\"Brmo3hBv\",\"posts_zju-event.md\":\"CTI-BvwC\",\"posts_zju-se-os.md\":\"D4JHDafp\",\"posts_zuckerberg-letter-post.md\":\"CHMyePoL\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"飞桨开源社区博客\",\"description\":\"Wonderful stories from PaddlePaddle contributors\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"postsPerPage\":10},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":true}");</script>
    
  </body>
</html>