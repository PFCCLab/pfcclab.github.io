import{_ as s,c as l,m as a,a as Q,L as T,o as n}from"./chunks/framework.CcfPirFf.js";const o="/assets/mha.BJRlaZVA.png",e="/assets/mla.BiTZsUeo.png",m="/assets/trans.Ca15I97b.png",i="/assets/gta.5a_vTZaC.png",r="/assets/gla.9YK_iv8i.png",k1=JSON.parse('{"title":"【论文分享】｜面向长文本的高效Attention基础结构设计","description":"","frontmatter":{"title":"【论文分享】｜面向长文本的高效Attention基础结构设计","date":"2025-06-24T00:00:00.000Z","author":{"name":"陶思睿","github":"Siritao"},"category":"insights"},"headers":[],"relativePath":"posts/attention-sharing-sirui.md","filePath":"posts/attention-sharing-sirui.md"}'),d={name:"posts/attention-sharing-sirui.md"},g={id:"mjx-1ec91c"},u={class:"MathJax",jax:"SVG",style:{position:"relative"}},h={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.227ex",height:"2.22ex",role:"img",focusable:"false",viewBox:"0 -694 984.3 981.2","aria-hidden":"true"},p={id:"mjx-b58ef0c"},L={class:"MathJax",jax:"SVG",style:{position:"relative"}},x={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.003ex",height:"1.65ex",role:"img",focusable:"false",viewBox:"0 -442 885.3 729.2","aria-hidden":"true"},w={id:"mjx-2cf97c4"},M={class:"MathJax",jax:"SVG",style:{position:"relative"}},H={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.227ex",height:"2.22ex",role:"img",focusable:"false",viewBox:"0 -694 984.3 981.2","aria-hidden":"true"},f={id:"mjx-f131784"},V={class:"MathJax",jax:"SVG",style:{position:"relative"}},_={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"6.124ex",height:"2.22ex",role:"img",focusable:"false",viewBox:"0 -694 2706.7 981.2","aria-hidden":"true"},v={id:"mjx-c091037"},A={class:"MathJax",jax:"SVG",style:{position:"relative"}},b={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.003ex",height:"1.65ex",role:"img",focusable:"false",viewBox:"0 -442 885.3 729.2","aria-hidden":"true"},Z={id:"mjx-adb6aa"},S={class:"MathJax",jax:"SVG",style:{position:"relative"}},C={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"7.282ex",height:"2.157ex",role:"img",focusable:"false",viewBox:"0 -666 3218.8 953.2","aria-hidden":"true"},j={id:"mjx-24e0ca5"},P={class:"MathJax",jax:"SVG",style:{position:"relative"}},D={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"11.478ex",height:"2.347ex",role:"img",focusable:"false",viewBox:"0 -750 5073.4 1037.2","aria-hidden":"true"},y={id:"mjx-b327916"},E={class:"MathJax",jax:"SVG",style:{position:"relative"}},k={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.003ex",height:"1.65ex",role:"img",focusable:"false",viewBox:"0 -442 885.3 729.2","aria-hidden":"true"},G={id:"mjx-20667f3"},I={class:"MathJax",jax:"SVG",style:{position:"relative"}},R={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.003ex",height:"1.65ex",role:"img",focusable:"false",viewBox:"0 -442 885.3 729.2","aria-hidden":"true"},B={id:"mjx-64ebc7"},q={class:"MathJax",jax:"SVG",style:{position:"relative"}},K={style:{"vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.184ex",height:"1.927ex",role:"img",focusable:"false",viewBox:"0 -694 965.2 851.8","aria-hidden":"true"},N={id:"mjx-0fb2f23"},J={class:"MathJax",jax:"SVG",style:{position:"relative"}},O={style:{"vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.184ex",height:"1.927ex",role:"img",focusable:"false",viewBox:"0 -694 965.2 851.8","aria-hidden":"true"},F={id:"mjx-ce95bee"},$={class:"MathJax",jax:"SVG",style:{position:"relative"}},U={style:{"vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"11.257ex",height:"1.927ex",role:"img",focusable:"false",viewBox:"0 -694 4975.5 851.8","aria-hidden":"true"},X={id:"mjx-34bc78"},z={class:"MathJax",jax:"SVG",style:{position:"relative"}},W={style:{"vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"6.183ex",height:"1.927ex",role:"img",focusable:"false",viewBox:"0 -694 2732.7 851.8","aria-hidden":"true"},Y={id:"mjx-59a89a5"},c={class:"MathJax",jax:"SVG",style:{position:"relative"}},Q1={style:{"vertical-align":"-0.439ex"},xmlns:"http://www.w3.org/2000/svg",width:"7.339ex",height:"2.009ex",role:"img",focusable:"false",viewBox:"0 -694 3243.7 888","aria-hidden":"true"},t1={id:"mjx-9a9e858"},T1={class:"MathJax",jax:"SVG",style:{position:"relative"}},a1={style:{"vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"19.279ex",height:"1.927ex",role:"img",focusable:"false",viewBox:"0 -694 8521.5 851.8","aria-hidden":"true"},l1={id:"mjx-7463a5a"},n1={class:"MathJax",jax:"SVG",style:{position:"relative"}},s1={style:{"vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"6.183ex",height:"1.927ex",role:"img",focusable:"false",viewBox:"0 -694 2732.7 851.8","aria-hidden":"true"},o1={id:"mjx-d4f0f9b"},e1={class:"MathJax",jax:"SVG",style:{position:"relative"}},m1={style:{"vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"6.183ex",height:"1.927ex",role:"img",focusable:"false",viewBox:"0 -694 2732.7 851.8","aria-hidden":"true"},i1={id:"mjx-ae06eb6"},r1={class:"MathJax",jax:"SVG",style:{position:"relative"}},d1={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"8.288ex",height:"2.157ex",role:"img",focusable:"false",viewBox:"0 -666 3663.5 953.2","aria-hidden":"true"},g1={tabindex:"0"},u1={id:"mjx-2c9a6f"},h1={class:"MathJax",jax:"SVG",style:{position:"relative"}},p1={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.227ex",height:"2.22ex",role:"img",focusable:"false",viewBox:"0 -694 984.3 981.2","aria-hidden":"true"},L1={id:"mjx-9925eba"},x1={class:"MathJax",jax:"SVG",style:{position:"relative"}},w1={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.003ex",height:"1.65ex",role:"img",focusable:"false",viewBox:"0 -442 885.3 729.2","aria-hidden":"true"},M1={id:"mjx-a906aef"},H1={class:"MathJax",jax:"SVG",style:{position:"relative"}},f1={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"3.358ex",height:"2.22ex",role:"img",focusable:"false",viewBox:"0 -694 1484.3 981.2","aria-hidden":"true"},V1={id:"mjx-179f5b2"},_1={class:"MathJax",jax:"SVG",style:{position:"relative"}},v1={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"3.358ex",height:"2.22ex",role:"img",focusable:"false",viewBox:"0 -694 1484.3 981.2","aria-hidden":"true"},A1={id:"mjx-9d5578a"},b1={class:"MathJax",jax:"SVG",style:{position:"relative"}},Z1={style:{"vertical-align":"-0.65ex"},xmlns:"http://www.w3.org/2000/svg",width:"3.134ex",height:"2.157ex",role:"img",focusable:"false",viewBox:"0 -666 1385.3 953.2","aria-hidden":"true"};function S1(C1,t,j1,P1,D1,y1){return n(),l("div",null,[t[129]||(t[129]=a("",7)),Q("ol",null,[Q("li",null,[t[2]||(t[2]=T("模型的 attention 计算量只与 ",-1)),Q("span",g,[Q("mjx-container",u,[(n(),l("svg",h,[...t[0]||(t[0]=[a("",1)])])),t[1]||(t[1]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"h"),Q("mi",null,"q")])])],-1))])]),t[3]||(t[3]=T(" 有关。",-1))]),Q("li",null,[t[10]||(t[10]=T("KV 头数的压缩带来两个好处： a) 直接减少缓存量，容纳更长文本、更大 batch； b) 在容易 memory bound 的推理场景下提高计算密度。GQA 的计算密度为 ",-1)),Q("span",p,[Q("mjx-container",L,[(n(),l("svg",x,[...t[4]||(t[4]=[a("",1)])])),t[5]||(t[5]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"g"),Q("mi",null,"q")])])],-1))])]),t[11]||(t[11]=T(" ，MQA 和 MLA 分别为 ",-1)),Q("span",w,[Q("mjx-container",M,[(n(),l("svg",H,[...t[6]||(t[6]=[a("",1)])])),t[7]||(t[7]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"h"),Q("mi",null,"q")])])],-1))])]),t[12]||(t[12]=T(" 和 ",-1)),Q("span",f,[Q("mjx-container",V,[(n(),l("svg",_,[...t[8]||(t[8]=[a("",1)])])),t[9]||(t[9]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mn",null,"2"),Q("mo",null,"×"),Q("msub",null,[Q("mi",null,"h"),Q("mi",null,"q")])])],-1))])]),t[13]||(t[13]=T(" （由于 RoPE dim 的存在，实际略小）。",-1))]),t[24]||(t[24]=Q("li",null,[T("固定 KV cache 大小下，模型的理论 expressiveness 大小关系：GQA < MLA < MQA。基于此，已有 TransMLA 等工作。 "),Q("img",{src:m,alt:"trans"})],-1)),Q("li",null,[t[19]||(t[19]=T("考虑并行性： ",-1)),Q("ul",null,[Q("li",null,[t[16]||(t[16]=T("GQA 可以受限地 TP（取决于 ",-1)),Q("span",v,[Q("mjx-container",A,[(n(),l("svg",b,[...t[14]||(t[14]=[a("",1)])])),t[15]||(t[15]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"g"),Q("mi",null,"q")])])],-1))])]),t[17]||(t[17]=T(" ）。",-1))]),t[18]||(t[18]=Q("li",null,"MLA、MQA 常采用 DP Attention（或 TP+DP，TP 会冗余复制 KV cache，而 DP 则会冗余复制 Attention 权重）；序列并行不受影响。",-1))])]),Q("li",null,[t[22]||(t[22]=T("考虑推理友好性，MQA、MLA 和 ",-1)),Q("span",Z,[Q("mjx-container",S,[(n(),l("svg",C,[...t[20]||(t[20]=[a("",1)])])),t[21]||(t[21]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"g"),Q("mi",null,"q")]),Q("mo",null,">"),Q("mn",null,"16")])],-1))])]),t[23]||(t[23]=T(" 的 GQA 可以在推理场景下充分使用 tensor core。",-1))])]),t[130]||(t[130]=a("",5)),Q("ul",null,[t[33]||(t[33]=Q("li",null,[Q("strong",null,"计算强度是关键指标"),T("：定义为计算量（FLOPs）与内存访问量（Bytes）之比。解码阶段需最大化算术强度（更多计算/字节），使计算从内存受限转向计算受限，充分利用 GPU 算力。")],-1)),Q("li",null,[t[29]||(t[29]=Q("strong",null,"组大小是杠杆",-1)),t[30]||(t[30]=T("： ",-1)),Q("span",j,[Q("mjx-container",P,[(n(),l("svg",D,[...t[25]||(t[25]=[a("",1)])])),t[26]||(t[26]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"g"),Q("mi",null,"q")]),Q("mo",null,"="),Q("msub",null,[Q("mi",null,"h"),Q("mi",null,"q")]),Q("mrow",{"data-mjx-texclass":"ORD"},[Q("mo",null,"/")]),Q("msub",null,[Q("mi",null,"h"),Q("mrow",{"data-mjx-texclass":"ORD"},[Q("mi",null,"k"),Q("mi",null,"v")])])])],-1))])]),t[31]||(t[31]=T(" 。增大 ",-1)),Q("span",y,[Q("mjx-container",E,[(n(),l("svg",k,[...t[27]||(t[27]=[a("",1)])])),t[28]||(t[28]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"g"),Q("mi",null,"q")])])],-1))])]),t[32]||(t[32]=T(" 可提高算术强度、减小 KV 缓存，但过大会损害并行性（需跨设备复制权重和缓存）。",-1))]),t[34]||(t[34]=Q("li",null,[Q("strong",null,"KV 复用与并行友好"),T("：理想方案需同时实现高算术强度、高效跨设备并行（零冗余或低冗余），且不牺牲模型质量。")],-1))]),t[131]||(t[131]=Q("h3",{id:"提出的解决方案-两种新型注意力机制",tabindex:"-1"},[T("提出的解决方案：两种新型注意力机制 "),Q("a",{class:"header-anchor",href:"#提出的解决方案-两种新型注意力机制","aria-label":'Permalink to "提出的解决方案：两种新型注意力机制"'},"​")],-1)),t[132]||(t[132]=Q("h4",{id:"grouped-tied-attention-gta",tabindex:"-1"},[T("Grouped-Tied Attention (GTA) "),Q("a",{class:"header-anchor",href:"#grouped-tied-attention-gta","aria-label":'Permalink to "Grouped-Tied Attention (GTA)"'},"​")],-1)),Q("ul",null,[t[44]||(t[44]=Q("li",null,[Q("strong",null,"核心思想"),T("：在 GQA 分组基础上，将 Key 和 Value 状态绑定（Tie）为一个共享状态，并仅对 Key 的部分维度应用位置编码（RoPE）。 "),Q("img",{src:i,alt:"gta"})],-1)),t[45]||(t[45]=Q("li",null,[Q("strong",null,"实现"),T("： "),Q("ol",null,[Q("li",null,"一个投影生成绑定 KV 状态（形状同单个 K 或 V 向量）。"),Q("li",null,"Value 路径使用整个绑定 KV 状态。"),Q("li",null,"Key 路径使用绑定 KV 状态的前半部分（不应用 RoPE） + 一个单独的单头投影（应用 RoPE）广播拼接而成。")])],-1)),Q("li",null,[t[42]||(t[42]=Q("strong",null,"优势",-1)),t[43]||(t[43]=T("： ",-1)),Q("ul",null,[Q("li",null,[t[37]||(t[37]=T("相比同 ",-1)),Q("span",G,[Q("mjx-container",I,[(n(),l("svg",R,[...t[35]||(t[35]=[a("",1)])])),t[36]||(t[36]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"g"),Q("mi",null,"q")])])],-1))])]),t[38]||(t[38]=T(" 的 GQA，KV 缓存减半（因 K 和 V 共享状态）。",-1))]),t[39]||(t[39]=Q("li",null,"算术强度翻倍（加载一次状态用于 K 和 V 计算）。",-1)),t[40]||(t[40]=Q("li",null,"保持 GQA 的并行友好性。",-1)),t[41]||(t[41]=Q("li",null,"实验证明质量匹配或优于 GQA（如 1.47B 模型，GTA-4 困惑度 10.12 vs GQA-4 的 10.20）。",-1))])])]),t[133]||(t[133]=Q("h4",{id:"grouped-latent-attention-gla",tabindex:"-1"},[T("Grouped Latent Attention (GLA) "),Q("a",{class:"header-anchor",href:"#grouped-latent-attention-gla","aria-label":'Permalink to "Grouped Latent Attention (GLA)"'},"​")],-1)),Q("ul",null,[Q("li",null,[t[48]||(t[48]=Q("strong",null,"核心思想",-1)),t[49]||(t[49]=T("：改进 MLA，将潜在表示分组（ ",-1)),Q("span",B,[Q("mjx-container",q,[(n(),l("svg",K,[...t[46]||(t[46]=[a("",1)])])),t[47]||(t[47]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"h"),Q("mi",null,"c")])])],-1))])]),t[50]||(t[50]=T(" 组），每组服务一个查询头子集，并减小每组潜在头维度。 ",-1)),t[51]||(t[51]=Q("img",{src:r,alt:"gla"},null,-1))]),Q("li",null,[t[67]||(t[67]=Q("strong",null,"实现",-1)),t[68]||(t[68]=T("： ",-1)),Q("ol",null,[Q("li",null,[t[58]||(t[58]=T("压缩 token 为 ",-1)),Q("span",N,[Q("mjx-container",J,[(n(),l("svg",O,[...t[52]||(t[52]=[a("",1)])])),t[53]||(t[53]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"h"),Q("mi",null,"c")])])],-1))])]),t[59]||(t[59]=T(" 个潜在头（而非 MLA 的单个头），每个头维度 ",-1)),Q("span",F,[Q("mjx-container",$,[(n(),l("svg",U,[...t[54]||(t[54]=[a("",1)])])),t[55]||(t[55]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"d"),Q("mi",null,"c")]),Q("mo",null,"="),Q("mn",null,"2"),Q("mo",null,"×"),Q("msub",null,[Q("mi",null,"d"),Q("mi",null,"h")])])],-1))])]),t[60]||(t[60]=T(" （MLA 为 ",-1)),Q("span",X,[Q("mjx-container",z,[(n(),l("svg",W,[...t[56]||(t[56]=[a("",1)])])),t[57]||(t[57]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mn",null,"4"),Q("mo",null,"×"),Q("msub",null,[Q("mi",null,"d"),Q("mi",null,"h")])])],-1))])]),t[61]||(t[61]=T(" ）。",-1))]),t[66]||(t[66]=Q("li",null,"每个潜在头及其上投影矩阵重建其组内查询头的独立 K/V 特征。",-1)),Q("li",null,[t[64]||(t[64]=T("解码时，潜在头可跨 TP 设备分片（如 ",-1)),Q("span",Y,[Q("mjx-container",c,[(n(),l("svg",Q1,[...t[62]||(t[62]=[a("",1)])])),t[63]||(t[63]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"h"),Q("mi",null,"c")]),Q("mo",null,"="),Q("mtext",null,"tp")])],-1))])]),t[65]||(t[65]=T(" 时零冗余）。",-1))])])]),Q("li",null,[t[85]||(t[85]=Q("strong",null,"优势",-1)),t[86]||(t[86]=T("： ",-1)),Q("ul",null,[Q("li",null,[t[75]||(t[75]=T("与 MLA 总缓存相当（如 GLA-2 缓存 ",-1)),Q("span",t1,[Q("mjx-container",T1,[(n(),l("svg",a1,[...t[69]||(t[69]=[a("",1)])])),t[70]||(t[70]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mn",null,"2"),Q("mo",null,"×"),Q("mn",null,"2"),Q("mo",null,"×"),Q("msub",null,[Q("mi",null,"d"),Q("mi",null,"h")]),Q("mo",null,"="),Q("mn",null,"4"),Q("mo",null,"×"),Q("msub",null,[Q("mi",null,"d"),Q("mi",null,"h")])])],-1))])]),t[76]||(t[76]=T(" ），但 TP 时每个设备缓存减半（如 TP=2 时，GLA-2 每设备缓存 ",-1)),Q("span",l1,[Q("mjx-container",n1,[(n(),l("svg",s1,[...t[71]||(t[71]=[a("",1)])])),t[72]||(t[72]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mn",null,"2"),Q("mo",null,"×"),Q("msub",null,[Q("mi",null,"d"),Q("mi",null,"h")])])],-1))])]),t[77]||(t[77]=T(" vs MLA 的 ",-1)),Q("span",o1,[Q("mjx-container",e1,[(n(),l("svg",m1,[...t[73]||(t[73]=[a("",1)])])),t[74]||(t[74]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mn",null,"4"),Q("mo",null,"×"),Q("msub",null,[Q("mi",null,"d"),Q("mi",null,"h")])])],-1))])]),t[78]||(t[78]=T(" ）。",-1))]),Q("li",null,[t[81]||(t[81]=T("算术强度高（ ",-1)),Q("span",i1,[Q("mjx-container",r1,[(n(),l("svg",d1,[...t[79]||(t[79]=[a("",1)])])),t[80]||(t[80]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mo",null,"≈"),Q("mn",null,"2"),Q("mo",null,"×"),Q("msub",null,[Q("mi",null,"g"),Q("mi",null,"q")])])],-1))])]),t[82]||(t[82]=T(" ），与 MQA 相当但质量更好。",-1))]),t[83]||(t[83]=Q("li",null,"并行友好：支持高效 TP 分片，避免 MLA 的缓存复制问题。",-1)),t[84]||(t[84]=Q("li",null,"实验证明质量匹配 MLA（如 1.47B 模型，GLA-2 平均下游准确率 60.0% vs MLA 的 59.1%），且更容忍负载不均衡。",-1))])])]),t[134]||(t[134]=Q("h2",{id:"小结",tabindex:"-1"},[T("小结 "),Q("a",{class:"header-anchor",href:"#小结","aria-label":'Permalink to "小结"'},"​")],-1)),Q("table",g1,[t[128]||(t[128]=Q("thead",null,[Q("tr",null,[Q("th",null,"方案"),Q("th",null,"KV 缓存"),Q("th",null,"算术强度"),Q("th",null,"并行友好性"),Q("th",null,"模型下游评测")])],-1)),Q("tbody",null,[t[127]||(t[127]=Q("tr",null,[Q("td",null,"MHA"),Q("td",null,"最大"),Q("td",null,"低"),Q("td",null,"TP 高效"),Q("td",null,"49.65")],-1)),Q("tr",null,[t[91]||(t[91]=Q("td",null,"MQA",-1)),t[92]||(t[92]=Q("td",null,"最小",-1)),Q("td",null,[t[89]||(t[89]=T("高（≈ ",-1)),Q("span",u1,[Q("mjx-container",h1,[(n(),l("svg",p1,[...t[87]||(t[87]=[a("",1)])])),t[88]||(t[88]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"h"),Q("mi",null,"q")])])],-1))])]),t[90]||(t[90]=T(" ）",-1))]),t[93]||(t[93]=Q("td",null,"TP 需复制全量 KV 缓存",-1)),t[94]||(t[94]=Q("td",null,"49.18",-1))]),Q("tr",null,[t[99]||(t[99]=Q("td",null,"GQA",-1)),t[100]||(t[100]=Q("td",null,"中等",-1)),Q("td",null,[t[97]||(t[97]=T("中等（≈ ",-1)),Q("span",L1,[Q("mjx-container",x1,[(n(),l("svg",w1,[...t[95]||(t[95]=[a("",1)])])),t[96]||(t[96]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msub",null,[Q("mi",null,"g"),Q("mi",null,"q")])])],-1))])]),t[98]||(t[98]=T(" ）",-1))]),t[101]||(t[101]=Q("td",null,"TP 受限",-1)),t[102]||(t[102]=Q("td",null,"48.27",-1))]),Q("tr",null,[t[107]||(t[107]=Q("td",null,"MLA",-1)),t[108]||(t[108]=Q("td",null,"小",-1)),Q("td",null,[t[105]||(t[105]=T("最高（≈ ",-1)),Q("span",M1,[Q("mjx-container",H1,[(n(),l("svg",f1,[...t[103]||(t[103]=[a("",1)])])),t[104]||(t[104]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mn",null,"2"),Q("msub",null,[Q("mi",null,"h"),Q("mi",null,"q")])])],-1))])]),t[106]||(t[106]=T(" ）",-1))]),t[109]||(t[109]=Q("td",null,"TP 需复制全量缓存",-1)),t[110]||(t[110]=Q("td",null,"49.24",-1))]),Q("tr",null,[t[115]||(t[115]=Q("td",null,"GLA",-1)),t[116]||(t[116]=Q("td",null,"小",-1)),Q("td",null,[t[113]||(t[113]=T("最高（≈ ",-1)),Q("span",V1,[Q("mjx-container",_1,[(n(),l("svg",v1,[...t[111]||(t[111]=[a("",1)])])),t[112]||(t[112]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mn",null,"2"),Q("msub",null,[Q("mi",null,"h"),Q("mi",null,"q")])])],-1))])]),t[114]||(t[114]=T(" ）",-1))]),t[117]||(t[117]=Q("td",null,"TP 受限",-1)),t[118]||(t[118]=Q("td",null,"49.29",-1))]),Q("tr",null,[t[123]||(t[123]=Q("td",null,"GTA",-1)),t[124]||(t[124]=Q("td",null,"小于 GQA",-1)),Q("td",null,[t[121]||(t[121]=T("高（≈ ",-1)),Q("span",A1,[Q("mjx-container",b1,[(n(),l("svg",Z1,[...t[119]||(t[119]=[a("",1)])])),t[120]||(t[120]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline"},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mn",null,"2"),Q("msub",null,[Q("mi",null,"g"),Q("mi",null,"q")])])],-1))])]),t[122]||(t[122]=T(" ）",-1))]),t[125]||(t[125]=Q("td",null,"TP 受限",-1)),t[126]||(t[126]=Q("td",null,"48.93",-1))])])]),t[135]||(t[135]=Q("blockquote",null,[Q("p",null,[Q("strong",null,"注"),T("：下游评测为我们固定了模型的参数量、train token 量，在 lm-evaluation-harness 上得到的 average acc（由于只 train 了一组，所以实际可能略有浮动，仅作参考）。")])],-1))])}const G1=s(d,[["render",S1]]);export{k1 as __pageData,G1 as default};
