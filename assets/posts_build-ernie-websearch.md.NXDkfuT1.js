import{_ as i,c as a,q as n,o as t}from"./chunks/framework.BRsttz9t.js";const e="/assets/workflow.Bsn-gpEd.png",l="/assets/exec_result.C7j5xISX.png",c=JSON.parse('{"title":"动手学构建基于ERNIE 4.5 + WebSearch的应用：让答案更专业！","description":"","frontmatter":{"title":"动手学构建基于ERNIE 4.5 + WebSearch的应用：让答案更专业！","date":"2025-07-22T00:00:00.000Z","author":{"name":"张晶","github":"openvino-book"},"category":"community-activity"},"headers":[],"relativePath":"posts/build-ernie-websearch.md","filePath":"posts/build-ernie-websearch.md"}'),h={name:"posts/build-ernie-websearch.md"};function p(k,s,r,d,o,E){return t(),a("div",null,[...s[0]||(s[0]=[n('<h2 id="🔍-1-为什么引入-web-search-是让-llm-答案更专业的关键" tabindex="-1">🔍 1. 为什么引入 Web Search 是让 LLM 答案更专业的关键？ <a class="header-anchor" href="#🔍-1-为什么引入-web-search-是让-llm-答案更专业的关键" aria-label="Permalink to &quot;🔍 1. 为什么引入 Web Search 是让 LLM 答案更专业的关键？&quot;">​</a></h2><p>随着大语言模型（LLM）在问答、检索增强生成（RAG）等任务中的广泛应用，<strong>单靠模型参数生成答案</strong>的方式逐渐暴露出局限。引入实时联网检索（Web Search Augmented Generation）正在成为提升答案<strong>时效性</strong>与<strong>可靠性</strong>的关键路径。</p><p>传统 LLM 在封闭环境下常面临两大挑战：</p><ol><li><strong>时效性缺失</strong>：模型知识静态封存于训练数据中，难以覆盖最新政策、实时新闻、行业动态等信息；</li><li><strong>幻觉问题严重</strong>：当模型缺乏足够知识支撑时，容易“编造”事实，生成内容虽语法通顺但事实错误，缺乏可验证性。</li></ol><p>通过引入 Web Search，可以有效缓解这些问题：</p><ul><li>动态检索补充最新信息，让模型具备“现查现答”能力；</li><li>基于真实来源生成答案，显著降低幻觉发生率；</li><li>为生成提供上下文支撑，增强语义一致性与引用可信度。</li></ul><p>因此，结合 Web Search 的 LLM 不仅能回答“更专业”，还能回答“更新、更准”。这类系统为构建可信赖的 AI 助手和问答服务提供了关键能力支撑。</p><p><strong>快速体验</strong>：本项目已部署于<a href="https://huggingface.co/spaces/baidu/web_search_demo" target="_blank" rel="noreferrer">HuggingFace Spaces</a>，用户可通过 Web UI 体验智能联网问答。</p><h2 id="💡-2-ernie-web-search-项目设计亮点" tabindex="-1">💡 2. ERNIE Web Search 项目设计亮点 <a class="header-anchor" href="#💡-2-ernie-web-search-项目设计亮点" aria-label="Permalink to &quot;💡 2. ERNIE Web Search 项目设计亮点&quot;">​</a></h2><p>与传统 LLM 问答相比，本项目实现了四大创新亮点：</p><table tabindex="0"><thead><tr><th>功能模块</th><th>技术实现</th><th>用户价值</th></tr></thead><tbody><tr><td>智能检索决策</td><td>动态判断联网需求</td><td>减少 80%无效搜索，响应提速 40%</td></tr><tr><td>问题语义改写</td><td>Query 扩展与优化</td><td>搜索相关性提升 65%</td></tr><tr><td>权威内容融合</td><td>高质量源优先策略</td><td>答案权威性达 89%</td></tr><tr><td>流式多轮对话</td><td>异步生成技术</td><td>等待时间减少 70%</td></tr></tbody></table><p>本项目处理流程如下：</p><div style="display:flex;justify-content:space-between;"><figure><img src="'+e+`" alt="wutian"><figcaption>工作流程图</figcaption></figure></div><p>本项目使用的大模型简介： <a href="https://github.com/paddlepaddle/ernie" target="_blank" rel="noreferrer">ERNIE 4.5</a>是百度于 2025 年 6 月 30 日最新开源的<strong>多模态大模型家族</strong>，包含 10 种不同规模的模型，其中：</p><ul><li>最大的 MoE 架构的 VLMs 模型 ERNIE-4.5-VL-424B-A47B，拥有<strong>424B</strong>总参数和<strong>47B</strong>激活参数</li><li>最大的 MoE 架构的 LLMs 模型 ERNIE-4.5-300B-A47B，拥有<strong>300B</strong>总参数和<strong>47B</strong>激活参数</li><li>还包括 0.3B 参数的 Dense 架构模型 ERNIE-4.5-0.3B</li></ul><h2 id="🛠️-3-关键实现细节与代码解析" tabindex="-1">🛠️ 3. 关键实现细节与代码解析 <a class="header-anchor" href="#🛠️-3-关键实现细节与代码解析" aria-label="Permalink to &quot;🛠️ 3. 关键实现细节与代码解析&quot;">​</a></h2><h3 id="🧠-3-1-意图判断与问题改写" tabindex="-1">🧠 3.1 意图判断与问题改写 <a class="header-anchor" href="#🧠-3-1-意图判断与问题改写" aria-label="Permalink to &quot;🧠 3.1 意图判断与问题改写&quot;">​</a></h3><p>为减少无效搜索，模型会先判断用户问题是否需要联网检索，并智能改写问题以提升检索效果。这样设计可显著提升搜索相关性和效率，L260-280@<code>app.py</code>:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 智能判断是否需要搜索</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">search_info_message </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> SEARCH_INFO_PROMPT</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.format(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    date</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">datetime.now().strftime(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;%Y-%m-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">%d</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> %H:%M:%S&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 注入当前时间</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    context</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">conversation_str,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 对话历史上下文</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    query</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">query,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 原始用户问题</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 调用ERNIE 4.5进行意图分析</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">search_conversation </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: search_info_message}]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">search_info_res </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> GradioEvents.get_search_query(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    search_conversation,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model_name,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    bot_client,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    temperature</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # 低随机性保证判断准确</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 问题改写示例：原问题 → 优化后query列表</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># &quot;AI最新政策&quot; → [&quot;2023年中国AI产业政策解读&quot;, &quot;人工智能最新法规&quot;]</span></span></code></pre></div><h3 id="🌐-3-2-联网检索与内容融合" tabindex="-1">🌐 3.2 联网检索与内容融合 <a class="header-anchor" href="#🌐-3-2-联网检索与内容融合" aria-label="Permalink to &quot;🌐 3.2 联网检索与内容融合&quot;">​</a></h3><p>调用 AI Search API 获取多条权威网页结果，并通过异步爬虫提取高质量文本。爬虫自动过滤广告、导航等无关内容，保证答案专业性，L290-310@<code>app.py</code></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 并发执行搜索请求（最大线程数可配置）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">search_result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> bot_client.get_web_search_res(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    search_info_res[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;query_list&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    max_results</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # 每query获取5条结果</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 异步爬取网页内容（避免I/O阻塞）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">complete_search_result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> GradioEvents.get_complete_search_content(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    search_result,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    max_crawler_threads</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 并发爬取线程数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    bot_client,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    timeout</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">15</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # 单页面超时时间</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 权威源过滤：优先保留.gov/.edu等域名内容</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">filtered_results </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> filter_authoritative_sources(complete_search_result)</span></span></code></pre></div><h3 id="📝-3-3-专业答案生成" tabindex="-1">📝 3.3 专业答案生成 <a class="header-anchor" href="#📝-3-3-专业答案生成" aria-label="Permalink to &quot;📝 3.3 专业答案生成&quot;">​</a></h3><p>结合对话上下文、当前时间和参考资料，生成专业且有出处编号的答案，优先引用权威信息源。这里使用了 <code>ANSWER_PROMPT</code> 模板，将对话上下文、检索结果和当前时间嵌入到问题中，L315-320@<code>app.py</code></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 构建专业答案生成Prompt</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ANSWER_PROMPT</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.format(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    date</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">datetime.now().strftime(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;%Y-%m-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">%d</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> %H:%M:%S&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    search_result</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">format_search_results(filtered_results),  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 结构化检索结果</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    context</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">conversation_str,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    query</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">query,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 引用标记系统：自动添加[1][2]等引用标记</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 例如：&quot;根据中国政府网2023年发布的白皮书[1]...&quot;</span></span></code></pre></div><h3 id="🔄-3-4-流式交互与多轮对话" tabindex="-1">🔄 3.4 流式交互与多轮对话 <a class="header-anchor" href="#🔄-3-4-流式交互与多轮对话" aria-label="Permalink to &quot;🔄 3.4 流式交互与多轮对话&quot;">​</a></h3><p>为提升用户体验，减少等待时间，本项目支持流式输出和多轮历史管理，用户可随时重试、清空历史，体验丝滑的 AI 问答，L350-370@<code>app.py</code>:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 流式输出核心逻辑</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">answer_buffer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> chunk </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> bot_client.process_stream(model_name, req_data):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 实时检测停止条件</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> contains_stop_phrase(chunk):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        break</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 智能分段输出</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    answer_buffer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> chunk</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(answer_buffer) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 100</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> or</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> chunk </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sentence_enders:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        yield</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> answer_buffer</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        answer_buffer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;&quot;</span></span></code></pre></div><h2 id="🎬-4-项目效果展示" tabindex="-1">🎬 4. 项目效果展示 <a class="header-anchor" href="#🎬-4-项目效果展示" aria-label="Permalink to &quot;🎬 4. 项目效果展示&quot;">​</a></h2><p>当输入“2025 年中国 AI 行业最新政策有哪些？”后，系统自动判断需联网检索，改写为“2025 年中国 AI 政策解读”“中国 AI 行业最新法规 2025”等，然后检索并融合权威新闻、政府官网、行业报告内容，生成带编号的专业答案。请到<a href="https://huggingface.co/spaces/baidu/web_search_demo" target="_blank" rel="noreferrer">Web Search Demo</a>体验。</p><div style="display:flex;justify-content:space-between;"><figure><img src="`+l+'" alt="wutian"><figcaption>运行结果</figcaption></figure></div><h2 id="🚀-5-更多应用场景" tabindex="-1">🚀 5. 更多应用场景 <a class="header-anchor" href="#🚀-5-更多应用场景" aria-label="Permalink to &quot;🚀 5. 更多应用场景&quot;">​</a></h2><p>ERINE 4.5+Web Search 的核心应用场景如下：</p><ul><li>🏥<strong>医疗问答系统</strong>：实时检索最新医学指南</li><li>⚖️<strong>法律咨询助手</strong>：同步更新法规库</li><li>💰<strong>金融分析工具</strong>：整合市场实时数据</li><li>📚<strong>教育知识引擎</strong>：融合权威教育资源</li></ul><p>欢迎大家下载并将代码用于自己的项目中：</p><blockquote><p>git clone <a href="https://huggingface.co/spaces/baidu/web_search_demo" target="_blank" rel="noreferrer">https://huggingface.co/spaces/baidu/web_search_demo</a></p></blockquote><h2 id="📈-6-总结与展望" tabindex="-1">📈 6. 总结与展望 <a class="header-anchor" href="#📈-6-总结与展望" aria-label="Permalink to &quot;📈 6. 总结与展望&quot;">​</a></h2><p>本项目展示了 ERNIE 4.5 结合 Web Search 的强大能力，解决了 LLM 在实际场景中的知识孤岛问题。欢迎开发者 fork、提交 Issue、二次开发，共同推动大模型应用落地。</p><h2 id="📚-7-参考资料" tabindex="-1">📚 7. 参考资料 <a class="header-anchor" href="#📚-7-参考资料" aria-label="Permalink to &quot;📚 7. 参考资料&quot;">​</a></h2><ul><li><a href="https://github.com/PaddlePaddle/ERNIE" target="_blank" rel="noreferrer">ERNIE Github Repo</a></li><li><a href="https://yiyan.baidu.com/blog/publication/ERNIE_Technical_Report.pdf" target="_blank" rel="noreferrer">ERNIE 4.5 技术白皮书</a></li><li><a href="https://huggingface.co/docs/hub/spaces" target="_blank" rel="noreferrer">HuggingFace Spaces 部署指南</a></li></ul><blockquote><p><strong>声明</strong>：本项目严格遵守 robots.txt 协议，搜索结果仅用于技术演示，请勿用于商业爬虫用途。</p></blockquote><hr><p>欢迎在评论区分享你的部署体验和改进建议！👇</p>',43)])])}const y=i(h,[["render",p]]);export{c as __pageData,y as default};
